{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised CARE Training\n",
    "Here we will train a plain N2V network on single noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? False\n",
      "WARNING: CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tifffile import imread\n",
    "\n",
    "from pn2v.unet import UNet\n",
    "from pn2v import utils\n",
    "from pn2v import training\n",
    "\n",
    "# See if we can use a GPU\n",
    "device=utils.getDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/Convallaria_diaphragm/'\n",
    "\n",
    "# Load the training data\n",
    "data=imread(path+'20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif')\n",
    "dataGT = np.mean(data,axis=0)[np.newaxis,...,np.newaxis]\n",
    "\n",
    "data=data[...,np.newaxis]\n",
    "\n",
    "dataGT = np.repeat(dataGT, 100, axis=0)\n",
    "print(data.shape,dataGT.shape)\n",
    "data = np.concatenate((data,dataGT),axis=-1)\n",
    "print(data.shape,dataGT.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(data[0,512:,512:,0])\n",
    "plt.show()\n",
    "plt.imshow(data[0,:512,512:,0])\n",
    "plt.show()\n",
    "plt.imshow(data[0,512:,:512,0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(data[0,:512,:512,0])\n",
    "plt.show()\n",
    "\n",
    "# We now crop away the data that has is to be used for testing\n",
    "data=np.concatenate( (data[:,512:,512:,:], data[:,:512,512:,:], data[:,512:,:512,:])  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Network and Train it\n",
    "This can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The N2V network requires only a single output unit per pixel\n",
    "net = UNet(1, depth=3)\n",
    "\n",
    "# Split training and validation data.\n",
    "my_train_data=data[:-5].copy()\n",
    "my_val_data=data[-5:].copy()\n",
    "\n",
    "# Start training.\n",
    "trainHist, valHist = training.trainNetwork(net=net, trainData=my_train_data, valData=my_val_data,\n",
    "                                           postfix='conv_CARE', directory=path, noiseModel=None,\n",
    "                                           device=device, numOfEpochs= 200, stepsPerEpoch=5, \n",
    "                                           virtualBatchSize=20, batchSize=1, learningRate=1e-3, supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the training and validation loss\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(valHist, label='validation loss')\n",
    "plt.plot(trainHist, label='training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
